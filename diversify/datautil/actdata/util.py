# -*- coding: utf-8 -*-
"""util

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jdYRnouVrSYCObxAmXHSjTKEVjlAr-6g
"""

# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.


import numpy as np
import torch
import random
import argparse
import os
from torchvision import transforms


def act_train():
    return transforms.Compose([
        transforms.ToTensor()
    ])

def loaddata_from_numpy(dataset='dsads', task='cross_people', root_dir='./data/act/'):
    if dataset == 'pamap' and task == 'cross_people':
        x = np.load(root_dir + dataset + '/' + dataset + '_x1.npy')
        ty = np.load(root_dir + dataset + '/' + dataset + '_y1.npy')
    else:
        x = np.load(root_dir + dataset + '/' + dataset + '_x.npy')
        ty = np.load(root_dir + dataset + '/' + dataset + '_y.npy')
    cy, py, sy = ty[:, 0], ty[:, 1], ty[:, 2]
    return x, cy, py, sy



def Nmax(args, d):
    for i in range(len(args.test_envs)):
        if d < args.test_envs[i]:
            return i
    return len(args.test_envs)


class basedataset(object):
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __getitem__(self, index):
        return self.x[index], self.y[index]

    def __len__(self):
        return len(self.x)


class mydataset(object):
    def __init__(self, args):
        self.x = None
        self.labels = None
        self.dlabels = None
        self.pclabels = None
        self.pdlabels = None
        self.task = None
        self.dataset = None
        self.transform = None
        self.target_transform = None
        self.loader = None
        self.args = args

    def set_labels(self, tlabels=None, label_type='domain_label'):
        assert len(tlabels) == len(self.x)
        if label_type == 'pclabel':
            self.pclabels = tlabels
        elif label_type == 'pdlabel':
            self.pdlabels = tlabels
        elif label_type == 'domain_label':
            self.dlabels = tlabels
        elif label_type == 'class_label':
            self.labels = tlabels

    def set_labels_by_index(self, tlabels=None, tindex=None, label_type='domain_label'):
        if label_type == 'pclabel':
            self.pclabels[tindex] = tlabels
        elif label_type == 'pdlabel':
            self.pdlabels[tindex] = tlabels
        elif label_type == 'domain_label':
            self.dlabels[tindex] = tlabels
        elif label_type == 'class_label':
            self.labels[tindex] = tlabels

    def target_trans(self, y):
        if self.target_transform is not None:
            return self.target_transform(y)
        else:
            return y

    def input_trans(self, x):
        if self.transform is not None:
            return self.transform(x)
        else:
            return x

    def __getitem__(self, index):
        x = self.input_trans(self.x[index])

        ctarget = self.target_trans(self.labels[index])
        dtarget = self.target_trans(self.dlabels[index])
        pctarget = self.target_trans(self.pclabels[index])
        pdtarget = self.target_trans(self.pdlabels[index])
        return x, ctarget, dtarget, pctarget, pdtarget, index

    def __len__(self):
        return len(self.x)


class subdataset(mydataset):
    def __init__(self, args, dataset, indices):
        super(subdataset, self).__init__(args)
        self.x = dataset.x[indices.astype(int)]
        self.loader = dataset.loader
        self.labels = dataset.labels[indices]
        self.dlabels = dataset.dlabels[indices] if dataset.dlabels is not None else None
        self.pclabels = dataset.pclabels[indices] if dataset.pclabels is not None else None
        self.pdlabels = dataset.pdlabels[indices] if dataset.pdlabels is not None else None
        self.task = dataset.task
        self.dataset = dataset.dataset
        self.transform = dataset.transform
        self.target_transform = dataset.target_transform


class combindataset(mydataset):
    def __init__(self, args, datalist):
        super(combindataset, self).__init__(args)
        self.domain_num = len(datalist)
        self.loader = datalist[0].loader
        xlist = [item.x for item in datalist]
        cylist = [item.labels for item in datalist]
        dylist = [item.dlabels for item in datalist]
        pcylist = [item.pclabels for item in datalist]
        pdylist = [item.pdlabels for item in datalist]
        self.dataset = datalist[0].dataset
        self.task = datalist[0].task
        self.transform = datalist[0].transform
        self.target_transform = datalist[0].target_transform
        self.x = torch.vstack(xlist)

        self.labels = np.hstack(cylist)
        self.dlabels = np.hstack(dylist)
        self.pclabels = np.hstack(pcylist) if pcylist[0] is not None else None
        self.pdlabels = np.hstack(pdylist) if pdylist[0] is not None else None
    
def set_random_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)

def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument('--dataset', type=str, default='emg')
    parser.add_argument('--task', type=str, default='cross_people')
    parser.add_argument('--data_dir', type=str, default='./data/')
    parser.add_argument('--algorithm', type=str, default='diversify')
    parser.add_argument('--seed', type=int, default=0)
    parser.add_argument('--latent_domain_num', type=int, default=5)
    parser.add_argument('--batch_size', type=int, default=64)
    parser.add_argument('--max_epoch', type=int, default=1)
    parser.add_argument('--local_epoch', type=int, default=1)
    parser.add_argument('--steps_per_epoch', type=int, default=100)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--lr_decay1', type=float, default=1.0)
    parser.add_argument('--lr_decay2', type=float, default=1.0)
    parser.add_argument('--beta1', type=float, default=0.9)
    parser.add_argument('--weight_decay', type=float, default=0.0005)
    parser.add_argument('--alpha', type=float, default=1.0)
    parser.add_argument('--alpha1', type=float, default=0.5)
    parser.add_argument('--lam', type=float, default=0.1)
    parser.add_argument('--bottleneck', type=int, default=256)
    parser.add_argument('--classifier', type=str, default='linear')
    parser.add_argument('--layer', type=str, default='bn')
    parser.add_argument('--dis_hidden', type=int, default=256)
    parser.add_argument('--num_classes', type=int, default=7)
    parser.add_argument('--test_envs', type=int, nargs='+', default=[1])
    parser.add_argument('--use_gnn', action='store_true')
    parser.add_argument('--N_WORKERS', type=int, default=2)

    args = parser.parse_args(args=[])  # This allows Colab to run argparse
    args.act_people = {'emg': [[1, 2, 3, 4, 5], [6, 7, 8, 9]]}
    return args

def print_row(items, colwidth=10):
    print(" | ".join(str(x).ljust(colwidth) for x in items))

def print_args(args, exclude=[]):
    arg_strs = []
    for k, v in vars(args).items():
        if k not in exclude:
            arg_strs.append(f"{k}: {v}")
    return "\n".join(arg_strs)

def train_valid_target_eval_names(args):
    return {'train': None, 'valid': None, 'target': None}

def alg_loss_dict(args):
    return ['class', 'dis']

def print_environ():
    print("Environment Summary:")
    print(f"Python Version: {os.sys.version}")
    print(f"Torch Version: {torch.__version__}")
    print(f"CUDA Available: {torch.cuda.is_available()}")
